### Sentiment Analysis
1. âš™ï¸ Modular Pipeline Architecture (DVC)
You transitioned from individual notebooks to a structured DVC (Data Version Control) pipeline. Each step of your project is now a "stage" defined in a dvc.yaml file.

ğŸ“¥ Data Ingestion: Automatically handles the collection of raw YouTube comment data.

ğŸ§¹ Preprocessing: Standardizes text cleaning and converts comments into mathematical features using TF-IDF.

ğŸ§  Model Building: Trains a LightGBM classifier specifically tuned for sentiment detection.

ğŸ“Š Model Evaluation: Calculates accuracy and generates confusion matrices to visualize errors.

2. ğŸ§ª Experiment Tracking & Registry (MLflow)
You integrated MLflow to move beyond local logging and manage the model lifecycle.

ğŸŒ Remote Tracking: You deployed an MLflow server on an AWS EC2 instance, allowing you to log every run to a central dashboard.

ğŸ“ˆ Metric Logging: The system captures training parameters and performance metrics for every single run.

ğŸ—ƒï¸ Model Registry: You implemented a system to "Register" successful models, versioning them (e.g., Version 1, Version 2) to track the best-performing weights.

3. â˜ï¸ Cloud Artifact Management (AWS S3)
Because ML models are too large for GitHub, you implemented a scalable cloud storage solution.

ğŸª£ AWS S3 Integration: You configured a bucket (bucket-mlflow-92) to act as your "Remote Storage".

ğŸ”— Artifact Decoupling: Large .pkl files are pushed to S3, while only small metadata "pointers" stay in Git, keeping your repo light.

ğŸ” IAM Security: You managed AWS IAM policies to ensure secure, authorized access to your cloud data.

4. ğŸ³ Containerization & CI/CD
To ensure your project works on any machine, you adopted modern deployment standards.

ğŸ“¦ Dockerization: You created a Dockerfile that packages your code and dependencies into a single container, eliminating environment errors.

ğŸ¤– GitHub Actions: You set up CI/CD to automatically verify your code and run the pipeline every time you commit new work.